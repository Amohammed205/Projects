{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Evaluating RBF Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports all the needed built in libraries\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import cuda\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.        ]\n",
      " [0.         0.00250627 0.        ]\n",
      " [0.         0.00501253 0.        ]\n",
      " ...\n",
      " [0.         1.         0.99498747]\n",
      " [0.         1.         0.99749373]\n",
      " [0.         1.         1.        ]]\n",
      "[[0.5488135  0.71518937 0.60276338]\n",
      " [0.54488318 0.4236548  0.64589411]\n",
      " [0.43758721 0.891773   0.96366276]\n",
      " [0.38344152 0.79172504 0.52889492]\n",
      " [0.56804456 0.92559664 0.07103606]\n",
      " [0.0871293  0.0202184  0.83261985]\n",
      " [0.77815675 0.87001215 0.97861834]\n",
      " [0.79915856 0.46147936 0.78052918]\n",
      " [0.11827443 0.63992102 0.14335329]\n",
      " [0.94466892 0.52184832 0.41466194]\n",
      " [0.26455561 0.77423369 0.45615033]\n",
      " [0.56843395 0.0187898  0.6176355 ]\n",
      " [0.61209572 0.616934   0.94374808]\n",
      " [0.6818203  0.3595079  0.43703195]\n",
      " [0.6976312  0.06022547 0.66676672]\n",
      " [0.67063787 0.21038256 0.1289263 ]\n",
      " [0.31542835 0.36371077 0.57019677]\n",
      " [0.43860151 0.98837384 0.10204481]\n",
      " [0.20887676 0.16130952 0.65310833]\n",
      " [0.2532916  0.46631077 0.24442559]\n",
      " [0.15896958 0.11037514 0.65632959]\n",
      " [0.13818295 0.19658236 0.36872517]\n",
      " [0.82099323 0.09710128 0.83794491]\n",
      " [0.09609841 0.97645947 0.4686512 ]\n",
      " [0.97676109 0.60484552 0.73926358]\n",
      " [0.03918779 0.28280696 0.12019656]\n",
      " [0.2961402  0.11872772 0.31798318]\n",
      " [0.41426299 0.0641475  0.69247212]\n",
      " [0.56660145 0.26538949 0.52324805]\n",
      " [0.09394051 0.5759465  0.9292962 ]\n",
      " [0.31856895 0.66741038 0.13179786]\n",
      " [0.7163272  0.28940609 0.18319136]\n",
      " [0.58651293 0.02010755 0.82894003]\n",
      " [0.00469548 0.67781654 0.27000797]\n",
      " [0.73519402 0.96218855 0.24875314]\n",
      " [0.57615733 0.59204193 0.57225191]\n",
      " [0.22308163 0.95274901 0.44712538]\n",
      " [0.84640867 0.69947928 0.29743695]\n",
      " [0.81379782 0.39650574 0.8811032 ]\n",
      " [0.58127287 0.88173536 0.69253159]\n",
      " [0.72525428 0.50132438 0.95608363]\n",
      " [0.6439902  0.42385505 0.60639321]\n",
      " [0.0191932  0.30157482 0.66017354]\n",
      " [0.29007761 0.61801543 0.4287687 ]\n",
      " [0.13547406 0.29828233 0.56996491]\n",
      " [0.59087276 0.57432525 0.65320082]\n",
      " [0.65210327 0.43141844 0.8965466 ]\n",
      " [0.36756187 0.43586493 0.89192336]\n",
      " [0.80619399 0.70388858 0.10022689]\n",
      " [0.91948261 0.7142413  0.99884701]]\n"
     ]
    }
   ],
   "source": [
    "# Define Constants\n",
    "sigma = .1\n",
    "npoints = 400\n",
    "nsources = 50\n",
    "\n",
    "# Constructs the Grid\n",
    "plot_grid = np.mgrid[0:1:npoints * 1j, 0:1:npoints * 1j]\n",
    "\n",
    "# Creats a 3 by 480000 matrix for targets\n",
    "targets_xy = np.vstack((plot_grid[0].ravel(),\n",
    "                        plot_grid[1].ravel(),\n",
    "                        np.zeros(plot_grid[0].size))).T\n",
    "targets_xz = np.vstack((plot_grid[0].ravel(),\n",
    "                        np.zeros(plot_grid[0].size),\n",
    "                        plot_grid[1].ravel())).T\n",
    "targets_yz = np.vstack((np.zeros(plot_grid[0].size),\n",
    "                       plot_grid[0].ravel(),\n",
    "                       plot_grid[1].ravel())).T\n",
    "\n",
    "targets = np.vstack((targets_xy, targets_xz, targets_yz))\n",
    "print(targets)\n",
    "\n",
    "# Creats a Random array of 3 by 50 of sources\n",
    "rand = np.random.RandomState(0)\n",
    "sources = rand.rand(nsources, 3)\n",
    "print(sources)\n",
    "\n",
    "# Copy the sources and targets to the compute device\n",
    "device_targets = cuda.to_device(targets)\n",
    "\n",
    "device_sources = cuda.to_device(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell creates a 3 by 480000 matrix for targets and a random array of 3 by 50 for sources. Sources and targets are then copied to the compute device using cuda.to_device()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the ThreadBlock\n",
    "SX = 16\n",
    "SY = 32\n",
    "# Define cj for f(x)\n",
    "weights = rand.rand(len(sources))\n",
    "\n",
    "@cuda.jit\n",
    "def rbf_evaluation_cuda(sources, targets, weights, IntArr):\n",
    "    \"\"\"Evaluate the RBF sum using cuda:\n",
    "    Inputs:\n",
    "        sources: Sources array\n",
    "        targets: Targets array\n",
    "        weights: Weights array\n",
    "        IntArr: Empty array for the intermediate results\"\"\"\n",
    "    \n",
    "    local_result = cuda.shared.array((SX, SY), numba.float32)\n",
    "    local_targets = cuda.shared.array((SX, 3), numba.float32)\n",
    "    local_sources = cuda.shared.array((SY, 3), numba.float32)\n",
    "    local_weights = cuda.shared.array(SY, numba.float32)\n",
    "    \n",
    "    # Local coordinates\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    # Global coordinates\n",
    "    px, py = cuda.grid(2)\n",
    "    \n",
    "    if px >= targets.shape[0]:\n",
    "        return\n",
    "    \n",
    "    # At first we are loading all the targets into the shared memory\n",
    "    # We use only the first column of threads to do this.\n",
    "    \n",
    "    if ty == 0:\n",
    "        for index in range(3):\n",
    "            local_targets[tx, index] = targets[px, index]\n",
    "    \n",
    "    # We are now loading all the sources and weights.\n",
    "    # We only require the first row of threads to do this.\n",
    "    \n",
    "    if tx == 0:\n",
    "        for index in range(3):\n",
    "            local_sources[ty, index] = sources[py, index]\n",
    "        local_weights[ty] = weights[py]\n",
    "        \n",
    "    # Let us now sync all threads\n",
    "    \n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Now compute the interactions\n",
    "    \n",
    "    squared_diff = numba.float32(0)\n",
    "    \n",
    "    for index in range(3):\n",
    "        squared_diff += (local_targets[tx, index] - local_sources[ty, index])**2\n",
    "    local_result[tx, ty] = math.exp(-squared_diff / (numba.float32(2) * numba.float32(sigma)**2)) * local_weights[ty]\n",
    "    \n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Now sum up all the local results into an intermediate array\n",
    "    \n",
    "    block_y = cuda.blockIdx.y\n",
    "    if ty == 0:\n",
    "        res = numba.float32(0)\n",
    "        for index in range(SY):\n",
    "            res += local_result[tx, index]\n",
    "        IntArr[px, block_y] = res  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above defines the function for the rbf evaluation with cuda. The function starts by defining all the local variables using the threadblock size. Local coordinates and global coordinates are then defined and used to move the threads from a local to a global position and split the grid into threadblocks. In each block the columns are summed and used to construct a (m,p) grid known as the intermediate array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.8632311e-03 3.0624286e-10]\n",
      " [1.9987950e-03 3.2998246e-10]\n",
      " [2.1429064e-03 3.5534681e-10]\n",
      " ...\n",
      " [8.0545660e-06 1.2174401e-08]\n",
      " [7.9701322e-06 1.0615391e-08]\n",
      " [7.8819048e-06 9.2506278e-09]]\n"
     ]
    }
   ],
   "source": [
    "# Defines the number of blocks in the horizontal and vertical\n",
    "lblocks = (targets.shape[0] + SX - 1) // SX\n",
    "pblocks = (sources.shape[0] + SY - 1) // SY\n",
    "\n",
    "# creates empty array\n",
    "IntArr = cuda.device_array((len(targets),pblocks), dtype=np.float32)\n",
    "\n",
    "# Uses function\n",
    "rbf_evaluation_cuda[(lblocks, pblocks), (SX, SY)](sources.astype('float32'), targets.astype('float32'), weights.astype('float32'), IntArr)\n",
    "\n",
    "IntArr = IntArr.copy_to_host()\n",
    "print(IntArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous cell was used to define the number of blocks in the horizontal and vertical and test the function. I tested the intermediate result using the visualise function from the lecture notes to make sure my graphs matched the provided ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summation Kernal\n",
    "\n",
    "@cuda.jit\n",
    "def sum_kernal(IntArr,results):\n",
    "    \"\"\"Evaluate the sum using cuda:\n",
    "    Inputs:\n",
    "        IntArr: Intermediate results\n",
    "        results: Empty array fro list of sums\"\"\"\n",
    "    # Local coordinates\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    # Global coordinates\n",
    "    px, py = cuda.grid(2)\n",
    "    \n",
    "    block_y = cuda.blockIdx.y\n",
    "    \n",
    "    res = numba.float32(0)\n",
    "    for i in range(block_y):\n",
    "        res += IntArr[px,i]\n",
    "    results[px] = res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summation kernal works by summing the rows in the (m,p) grid and putting the values in a list of m length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8632311e-03 1.9987950e-03 2.1429064e-03 ... 8.0545660e-06 7.9701322e-06\n",
      " 7.8819048e-06]\n"
     ]
    }
   ],
   "source": [
    "# The use of the summation kernal\n",
    "results = cuda.device_array(len(targets), dtype=np.float32)\n",
    "\n",
    "sum_kernal[(lblocks, pblocks), (SX, SY)](IntArr,results)\n",
    "results = results.copy_to_host()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU version of the rbf evaluation so the results arrays can be compared \n",
    "@numba.njit(parallel=True)\n",
    "def rbf_evaluation(sources, targets, weights, result):\n",
    "    \"\"\"Evaluate the RBF sum.\"\"\"\n",
    "    \n",
    "    n = len(sources)\n",
    "    m = len(targets)\n",
    "        \n",
    "    result[:] = 0\n",
    "    for index in numba.prange(m):\n",
    "        result[index] = np.sum(np.exp(-np.sum(np.abs(targets[index] - sources)**2, axis=1) / (2 * sigma**2)) * weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8632307e-03 1.9987959e-03 2.1429050e-03 ... 8.0667323e-06 7.9807414e-06\n",
      " 7.8911480e-06]\n"
     ]
    }
   ],
   "source": [
    "result = np.zeros(len(targets), dtype=np.float32)\n",
    "rbf_evaluation(sources, targets, weights, result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from both lists my cuda implementation of rbf evaluation does work as every value is the same to 1 decimal place and both give the same visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8 ms ± 224 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "rbf_evaluation_cuda[(lblocks, pblocks), (SX, SY)](sources.astype('float32'), targets.astype('float32'), weights.astype('float32'), IntArr)\n",
    "sum_kernal[(lblocks, pblocks), (SX, SY)](IntArr, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241 ms ± 666 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rbf_evaluation(sources, targets, weights, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the displayed times the cuda implementation is more than 20 times faster. As the value of nsources increases the CPU implementation time increased at a higher rate than the GPU implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Evaluating the discrete Laplacian on GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU implementation\n",
    "\n",
    "@cuda.jit\n",
    "def discretise_poisson_cuda(N, row_ind, col_ind, resultArr, f):\n",
    "    \"\"\"Generate the matrix and rhs associated with the discrete Poisson operator in cuda:\n",
    "        Inputs:\n",
    "        N: The dimension\n",
    "        row_ind: Row indices\n",
    "        col_ind: Column indices\n",
    "        resultArr: Empty array of results\n",
    "        f: Binary array\n",
    "        \"\"\"\n",
    "    \n",
    "    # Local coordinates\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    # Global coordinates\n",
    "    px, py = cuda.grid(2)\n",
    "    \n",
    "    if ty == 0 and tx == 0:\n",
    "        count = 0\n",
    "        \n",
    "    else:\n",
    "        if tx == 0 or tx == N - 1 or ty == 0 or ty == N - 1:\n",
    "            row_ind[count] = col_ind[count] = ty * N + tx\n",
    "            resultArr[count] =  1\n",
    "            f[ty * N + tx] = 0\n",
    "            count += 1\n",
    "        else:\n",
    "            row_ind[count : count + 5] = ty * N + tx\n",
    "            col_ind[count] = ty * N + tx\n",
    "            col_ind[count + 1] = ty * N + tx + 1\n",
    "            col_ind[count + 2] = ty * N + tx - 1\n",
    "            col_ind[count + 3] = (ty + 1) * N + tx\n",
    "            col_ind[count + 4] = (ty - 1) * N + tx\n",
    "                                \n",
    "            resultArr[count] = 4 * (N - 1)**2\n",
    "            resultArr[count + 1 : count + 5] = - (N - 1)**2\n",
    "            f[ty * N + tx] = 1\n",
    "                \n",
    "            count += 5         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above defines the function for the discrete Laplacian with cuda. The function sets a counter at the first thread in the grid and proceeds to check if the next thread is at the boundary of the grid or not. If a thread is at the boundary of the grid its value in the results array will be assigned to 1 and 0 in the binary array f. If the thread is not at the boundary of the grid the values in the results array will be determined by $4(N - 1)^2$ and $-(N - 1)^2$ a 1 will be added to f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining required terms\n",
    "N = 10\n",
    "\n",
    "nelements = 5 * N**2 - 16 * N + 16\n",
    "\n",
    "row_ind = cuda.device_array(nelements, dtype=np.float64)\n",
    "col_ind = cuda.device_array(nelements, dtype=np.float64)\n",
    "resultArr = cuda.device_array(nelements, dtype=np.float64)\n",
    "\n",
    "f = cuda.device_array(N*N, dtype=np.float64)\n",
    "\n",
    "# Using function\n",
    "discretise_poisson_cuda[(16,16), (N,N)](N, row_ind, col_ind, resultArr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(f.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained the correct array for the binary representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1. -81. -81. -81. -81.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(resultArr.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was unable to correctly output the results array when compared to the CPU implementation below. I believe this is due to the count not being recorded correctly leading to the incorrect placement of terms. I was able to resolve by adding the for loops from the cpu implementation, but this did not seem to be the correct method as it did not utilise cudas ability to run loops alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def discretise_poisson(N):\n",
    "    \"\"\"Generate the matrix and rhs associated with the discrete Poisson operator.\"\"\"\n",
    "    \n",
    "    nelements = 5 * N**2 - 16 * N + 16\n",
    "    \n",
    "    row_ind = np.empty(nelements, dtype=np.float64)\n",
    "    col_ind = np.empty(nelements, dtype=np.float64)\n",
    "    data = np.empty(nelements, dtype=np.float64)\n",
    "    \n",
    "    f = np.empty(N * N, dtype=np.float64)\n",
    "    \n",
    "    count = 0\n",
    "    for j in range(N):\n",
    "        for i in range(N):\n",
    "            if i == 0 or i == N - 1 or j == 0 or j == N - 1:\n",
    "                row_ind[count] = col_ind[count] = j * N + i\n",
    "                data[count] =  0\n",
    "                f[j * N + i] = 0\n",
    "                count += 1\n",
    "                \n",
    "            else:\n",
    "                row_ind[count : count + 5] = j * N + i\n",
    "                col_ind[count] = j * N + i\n",
    "                col_ind[count + 1] = j * N + i + 1\n",
    "                col_ind[count + 2] = j * N + i - 1\n",
    "                col_ind[count + 3] = (j + 1) * N + i\n",
    "                col_ind[count + 4] = (j - 1) * N + i\n",
    "                                \n",
    "                data[count] = 4 * (N - 1)**2\n",
    "                data[count + 1 : count + 5] = - (N - 1)**2\n",
    "                f[j * N + i] = 1\n",
    "                \n",
    "                count += 5\n",
    "                                                \n",
    "    return coo_matrix((data, (row_ind, col_ind)), shape=(N**2, N**2)).tocsr(), f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "A,f = discretise_poisson(10)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -81. -81. 324.\n",
      " -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81. -81.\n",
      " 324. -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81.\n",
      " -81. 324. -81. -81. -81. -81. 324. -81. -81.   0.   0. -81. -81. 324.\n",
      " -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81. -81.\n",
      " 324. -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81.\n",
      " -81. 324. -81. -81. -81. -81. 324. -81. -81.   0.   0. -81. -81. 324.\n",
      " -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81. -81.\n",
      " 324. -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81.\n",
      " -81. 324. -81. -81. -81. -81. 324. -81. -81.   0.   0. -81. -81. 324.\n",
      " -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81. -81.\n",
      " 324. -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81.\n",
      " -81. 324. -81. -81. -81. -81. 324. -81. -81.   0.   0. -81. -81. 324.\n",
      " -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81. -81.\n",
      " 324. -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81.\n",
      " -81. 324. -81. -81. -81. -81. 324. -81. -81.   0.   0. -81. -81. 324.\n",
      " -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81. -81.\n",
      " 324. -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81.\n",
      " -81. 324. -81. -81. -81. -81. 324. -81. -81.   0.   0. -81. -81. 324.\n",
      " -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81. -81.\n",
      " 324. -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81.\n",
      " -81. 324. -81. -81. -81. -81. 324. -81. -81.   0.   0. -81. -81. 324.\n",
      " -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81. -81.\n",
      " 324. -81. -81. -81. -81. 324. -81. -81. -81. -81. 324. -81. -81. -81.\n",
      " -81. 324. -81. -81. -81. -81. 324. -81. -81.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(A.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620 µs ± 11 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit discretise_poisson_cuda[(16,16), (N,N)](N, row_ind, col_ind, resultArr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 µs ± 3.56 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit discretise_poisson(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from above the time it took the cuda implementation was longer than the CPU implementation which is not the expected result. I believe this is due to the error in my cuda implementation. If this error were to be resolved I am confident that the cuda implementation will be faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Solving modifed Helmholtz problems with CG on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import LinearOperator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
